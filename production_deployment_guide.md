# ğŸš€ NEULBO ML Server í”„ë¡œë•ì…˜ ë°°í¬ ê°€ì´ë“œ

## ğŸ“‹ ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… **í˜„ì¬ ì¤€ë¹„ ì™„ë£Œ ì‚¬í•­**
- [x] FastAPI ì„œë²„ êµ¬ì¶• ì™„ë£Œ
- [x] PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™
- [x] XGBoost ML ëª¨ë¸ í†µí•©
- [x] ìˆ˜ë©´ ë¶„ì„ API ì™„ì„±
- [x] LLM í”¼ë“œë°± ê¸°ëŠ¥ ì¶”ê°€
- [x] ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [x] ì—ëŸ¬ í•¸ë“¤ë§ êµ¬í˜„
- [x] API ë¬¸ì„œ ìë™ ìƒì„± (FastAPI Swagger)

### ğŸ”§ **ì‚¬ì „ ì¤€ë¹„ í•„ìˆ˜ ì‚¬í•­**

#### 1. **í™˜ê²½ ì„¤ì •**
```bash
# 1. í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ìƒì„±
cp env.example .env

# 2. í”„ë¡œë•ì…˜ ì„¤ì • ìˆ˜ì •
vim .env
```

**ì£¼ìš” ì„¤ì •ê°’:**
```env
# ë°ì´í„°ë² ì´ìŠ¤ (í”„ë¡œë•ì…˜ DB ì •ë³´ë¡œ ë³€ê²½)
DATABASE_URL="postgresql://username:password@localhost:5432/neulbo_db"

# ë³´ì•ˆ (ë°˜ë“œì‹œ ë³€ê²½!)
SECRET_KEY="your-production-secret-key-here"

# ì„œë²„ ì„¤ì •
HOST="0.0.0.0"
PORT=8000
LOG_LEVEL="INFO"

# OLLAMA LLM ì„œë²„
OLLAMA_URL="http://ollama-container:11434"  # ë„ì»¤ í™˜ê²½
LLM_MODEL="gpt-oss:20b"
```

#### 2. **ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜**
```bash
# LLM í”¼ë“œë°± í…Œì´ë¸” ìƒì„±
python create_migration.py
```

#### 3. **OLLAMA ì„œë²„ ì„¤ì •**
```bash
# OLLAMA ë„ì»¤ ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker run -d --name ollama-server \
  -p 11434:11434 \
  -v ollama:/root/.ollama \
  ollama/ollama

# gpt-oss:20b ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
docker exec -it ollama-server ollama pull gpt-oss:20b
```

#### 4. **ì˜ì¡´ì„± ì„¤ì¹˜**
```bash
pip install -r requirements.txt
```

## ğŸ³ **Docker ë°°í¬ (ê¶Œì¥)**

### Dockerfile ìƒì„±
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# ì„œë²„ ì‹¤í–‰
CMD ["python", "-m", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### docker-compose.yml
```yaml
version: '3.8'

services:
  ml-server:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/neulbo_db
      - OLLAMA_URL=http://ollama:11434
    depends_on:
      - db
      - ollama
    volumes:
      - ./app/ml_models:/app/app/ml_models
    networks:
      - neulbo-network

  db:
    image: postgres:15
    environment:
      POSTGRES_DB: neulbo_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - neulbo-network

  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - neulbo-network

volumes:
  postgres_data:
  ollama_data:

networks:
  neulbo-network:
    driver: bridge
```

### ë°°í¬ ëª…ë ¹ì–´
```bash
# 1. ì»¨í…Œì´ë„ˆ ë¹Œë“œ ë° ì‹¤í–‰
docker-compose up -d

# 2. ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±
docker-compose exec ml-server python create_migration.py

# 3. OLLAMA ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
docker-compose exec ollama ollama pull gpt-oss:20b

# 4. ìƒíƒœ í™•ì¸
docker-compose ps
```

## ğŸ”§ **ì§ì ‘ ë°°í¬ (ì„œë²„ì—ì„œ)**

### 1. ì„œë²„ í™˜ê²½ ì¤€ë¹„
```bash
# PostgreSQL ì„¤ì¹˜ ë° ì„¤ì •
sudo apt update
sudo apt install postgresql postgresql-contrib

# ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
sudo -u postgres createdb neulbo_db
```

### 2. OLLAMA ì„¤ì¹˜
```bash
# OLLAMA ì„¤ì¹˜
curl -fsSL https://ollama.ai/install.sh | sh

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull gpt-oss:20b
```

### 3. ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
```bash
# í”„ë¡œë•ì…˜ ì„œë²„ ì‹¤í–‰
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

## ğŸš¦ **ë°°í¬ í›„ í™•ì¸ì‚¬í•­**

### 1. **í—¬ìŠ¤ì²´í¬**
```bash
# API ì„œë²„ ìƒíƒœ
curl http://localhost:8000/api/v1/health/check

# LLM ì„œë¹„ìŠ¤ ìƒíƒœ  
curl http://localhost:8000/api/v1/llm/health/llm
```

### 2. **ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸**
```bash
# ìˆ˜ë©´ ë¶„ì„ í…ŒìŠ¤íŠ¸
python quick_test.py

# LLM í”¼ë“œë°± í…ŒìŠ¤íŠ¸
python test_llm_feedback.py
```

### 3. **ë¡œê·¸ ëª¨ë‹ˆí„°ë§**
```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸
tail -f logs/app.log

# ë„ì»¤ ë¡œê·¸ í™•ì¸
docker-compose logs -f ml-server
```

## âš ï¸ **ì£¼ì˜ì‚¬í•­**

### ë³´ì•ˆ
- [ ] `SECRET_KEY` ë°˜ë“œì‹œ ë³€ê²½
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ë¹„ë°€ë²ˆí˜¸ ê°•í™”
- [ ] CORS ì„¤ì • í™•ì¸
- [ ] ë°©í™”ë²½ í¬íŠ¸ ì„¤ì •

### ì„±ëŠ¥
- [ ] Worker í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì¡°ì • (CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ)
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì»¤ë„¥ì…˜ í’€ ì„¤ì •
- [ ] ë¡œë“œë°¸ëŸ°ì„œ êµ¬ì„± (í•„ìš”ì‹œ)

### ëª¨ë‹ˆí„°ë§
- [ ] ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶•
- [ ] ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ ì„¤ì •
- [ ] ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì„±

## ğŸ¤ **SpringBoot ì„œë²„ì™€ ì—°ë™**

### ê³µìœ  ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ë¶„ë¦¬
```
SpringBoot ì„œë²„ ë‹´ë‹¹:
- users (ì‚¬ìš©ì ê´€ë¦¬)
- ê¸°íƒ€ ì•± ê¸°ëŠ¥ë“¤

ML Server ë‹´ë‹¹:
- sleep_analyses (ìˆ˜ë©´ ë¶„ì„)
- sleep_stage_intervals
- stage_probabilities  
- llm_feedbacks (LLM í”¼ë“œë°±)
- model_info
- system_health
```

### API í†µì‹ 
- SpringBoot â†’ ML Server: í•„ìš”ì‹œ HTTP API í˜¸ì¶œ
- ê³µìœ  DBë¥¼ í†µí•œ ë°ì´í„° êµí™˜ ê°€ëŠ¥

## ğŸ“Š **ì„±ëŠ¥ ì˜ˆìƒ**

**ì˜ˆìƒ ì²˜ë¦¬ëŸ‰:**
- ìˆ˜ë©´ ë¶„ì„: ~10-20 ìš”ì²­/ë¶„
- LLM í”¼ë“œë°±: ~5-10 ìš”ì²­/ë¶„
- ë™ì‹œ ì‚¬ìš©ì: ~50-100ëª…

**ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­:**
- CPU: 4 ì½”ì–´ (XGBoost + LLM)
- RAM: 8GB (ëª¨ë¸ ë¡œë”© + ì²˜ë¦¬)
- ë””ìŠ¤í¬: 50GB (ë¡œê·¸, ëª¨ë¸ íŒŒì¼)
